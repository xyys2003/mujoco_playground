{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7b2cde",
   "metadata": {},
   "source": [
    "# Rollout rgb_ppo ONNX in MuJoCo (AirbotPlayPickCube)\n",
    "\n",
    "This notebook runs an exported **rgb_ppo** policy (ONNX) inside a MuJoCo XML (`mjx_single_cube.xml`) and records a video.\n",
    "\n",
    "**Default run directory:** `/data/user/junzhe/code/mjpl/mujoco_playground/learning/runs/rgbppo_AirbotPlayPickCube__1__1766164466`\n",
    "\n",
    "Notes:\n",
    "- The notebook **auto-detects ONNX input signature**:\n",
    "  - vector obs: `(B, D)`\n",
    "  - image-only: `(B, H, W, C)` or `(B, C, H, W)`\n",
    "  - image+state: two inputs (one 4D image tensor + one 2D state tensor)\n",
    "- For **pure-vision**, you should export a **rgb-only** ONNX (no `state` input). If your ONNX expects `state`, this notebook can feed zeros by default, but that usually degrades performance unless your `state` matches training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f160dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ONNX_PATH = /data/user/junzhe/code/mjpl/mujoco_playground/learning/runs/debug_pick_init_pos2/policy_rgb_state.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# --- Paths (edit if needed) ---\n",
    "RUN_DIR = r\"/data/user/junzhe/code/mjpl/mujoco_playground/learning/runs/debug_pick_init_pos2\"\n",
    "XML_PATH = r\"/data/user/junzhe/code/mjpl/mujoco_playground/mujoco_playground/_src/manipulation/airbot_play/xmls/mjx_single_cube.xml\"\n",
    "\n",
    "# Pick ONE of these (prefer rgb-only for \"pure vision\"):\n",
    "ONNX_RGB_ONLY = os.path.join(RUN_DIR, \"policy_rgb.onnx\")\n",
    "ONNX_RGB_STATE = os.path.join(RUN_DIR, \"policy_rgb_state.onnx\")\n",
    "\n",
    "ONNX_PATH = ONNX_RGB_ONLY if os.path.exists(ONNX_RGB_ONLY) else ONNX_RGB_STATE\n",
    "print(\"Using ONNX_PATH =\", ONNX_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbbc0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: set MUJOCO_GL before importing mujoco\n",
    "import os\n",
    "os.environ.setdefault(\"MUJOCO_GL\", \"egl\")\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=200)\n",
    "\n",
    "import mujoco\n",
    "import mediapy\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe7333",
   "metadata": {},
   "source": [
    "## Inspect ONNX inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb598ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "  action ['batch', 7] tensor(float)\n",
      "Inputs:\n",
      "  rgb ['batch', 128, 128, 3] tensor(uint8)\n",
      "  state ['batch', 50] tensor(float)\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(XML_PATH), f\"XML not found: {XML_PATH}\"\n",
    "assert os.path.exists(ONNX_PATH), f\"ONNX not found: {ONNX_PATH}\"\n",
    "\n",
    "sess = ort.InferenceSession(ONNX_PATH, providers=[\"CPUExecutionProvider\"])\n",
    "print(\"Outputs:\")\n",
    "for o in sess.get_outputs():\n",
    "    print(\" \", o.name, o.shape, o.type)\n",
    "print(\"Inputs:\")\n",
    "for i in sess.get_inputs():\n",
    "    print(\" \", i.name, i.shape, i.type)\n",
    "\n",
    "inputs = sess.get_inputs()\n",
    "outputs = sess.get_outputs()\n",
    "out_name = outputs[0].name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471c9db",
   "metadata": {},
   "source": [
    "## Helpers: resize/render + ONNX feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d6190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected ONNX layout: image_state\n"
     ]
    }
   ],
   "source": [
    "def _shape_len(x):\n",
    "    try:\n",
    "        return len(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _is_image_shape(shape):\n",
    "    # Accept common 4D forms: (B,H,W,C) or (B,C,H,W)\n",
    "    return _shape_len(shape) == 4\n",
    "\n",
    "def _is_vector_shape(shape):\n",
    "    return _shape_len(shape) == 2\n",
    "\n",
    "def _infer_io_layout(input_info):\n",
    "    \"\"\"Return dict describing expected inputs.\"\"\"\n",
    "    infos = [{\"name\": i.name, \"shape\": i.shape, \"type\": i.type} for i in input_info]\n",
    "    image_inputs = [x for x in infos if _is_image_shape(x[\"shape\"])]\n",
    "    vec_inputs = [x for x in infos if _is_vector_shape(x[\"shape\"])]\n",
    "\n",
    "    layout = {\"mode\": None, \"image\": None, \"state\": None, \"vector\": None}\n",
    "    if len(infos) == 1 and image_inputs:\n",
    "        layout[\"mode\"] = \"image_only\"\n",
    "        layout[\"image\"] = image_inputs[0]\n",
    "    elif len(infos) == 2 and len(image_inputs) == 1 and len(vec_inputs) == 1:\n",
    "        layout[\"mode\"] = \"image_state\"\n",
    "        layout[\"image\"] = image_inputs[0]\n",
    "        layout[\"state\"] = vec_inputs[0]\n",
    "    elif len(infos) == 1 and vec_inputs:\n",
    "        layout[\"mode\"] = \"vector_only\"\n",
    "        layout[\"vector\"] = vec_inputs[0]\n",
    "    else:\n",
    "        layout[\"mode\"] = \"unknown\"\n",
    "    return layout\n",
    "\n",
    "layout = _infer_io_layout(inputs)\n",
    "print(\"Detected ONNX layout:\", layout[\"mode\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04706d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rgb(renderer: mujoco.Renderer, data: mujoco.MjData, camera: str) -> np.ndarray:\n",
    "    \"\"\"Return RGB uint8 image in HWC.\"\"\"\n",
    "    renderer.update_scene(data, camera=camera)\n",
    "    img = renderer.render()\n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def resize_hwc_uint8(img: np.ndarray, H: int, W: int) -> np.ndarray:\n",
    "    \"\"\"Resize HWC uint8 to (H,W,3).\"\"\"\n",
    "    pil = Image.fromarray(img)\n",
    "    pil = pil.resize((W, H), resample=Image.BILINEAR)\n",
    "    out = np.asarray(pil, dtype=np.uint8)\n",
    "    if out.ndim == 2:\n",
    "        out = np.repeat(out[..., None], 3, axis=2)\n",
    "    if out.shape[-1] == 4:\n",
    "        out = out[..., :3]\n",
    "    return out\n",
    "\n",
    "def to_onnx_image(img_hwc_u8: np.ndarray, image_input) -> np.ndarray:\n",
    "    \"\"\"Pack image into expected ONNX image tensor (batch included).\"\"\"\n",
    "    shape = image_input[\"shape\"]  # e.g., [None, H, W, 3] or [None, 3, H, W]\n",
    "    typ = image_input[\"type\"]\n",
    "\n",
    "    # Determine expected H/W/C positions\n",
    "    # If second dim is 3, assume NCHW; else assume NHWC.\n",
    "    is_nchw = (shape[1] == 3) if (len(shape) == 4 and isinstance(shape[1], int)) else False\n",
    "\n",
    "    x = img_hwc_u8\n",
    "    if is_nchw:\n",
    "        x = np.transpose(x, (2, 0, 1))  # CHW\n",
    "    x = x[None, ...]  # add batch\n",
    "\n",
    "    # Cast based on input type\n",
    "    if \"uint8\" in typ:\n",
    "        return x.astype(np.uint8)\n",
    "    else:\n",
    "        # Most exported graphs cast to float internally anyway; float32 is safe.\n",
    "        return x.astype(np.float32)\n",
    "\n",
    "def to_onnx_state(state_vec: np.ndarray, state_input) -> np.ndarray:\n",
    "    typ = state_input[\"type\"]\n",
    "    x = state_vec[None, :]\n",
    "    if \"float\" in typ:\n",
    "        return x.astype(np.float32)\n",
    "    return x.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ce0a1",
   "metadata": {},
   "source": [
    "## (Optional) Vector obs builder\n",
    "Only used if your ONNX was accidentally exported as a vector-only policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d77ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ARM_JOINTS = [\"joint1\", \"joint2\", \"joint3\", \"joint4\", \"joint5\", \"joint6\"]\n",
    "_FINGER_JOINTS = [\"endleft\", \"endright\"]\n",
    "\n",
    "def build_vector_obs(model: mujoco.MjModel, data: mujoco.MjData) -> np.ndarray:\n",
    "    \"\"\"A best-effort vector obs (may NOT match training).\"\"\"\n",
    "    gripper_site_id = model.site(\"endpoint\").id\n",
    "    obj_body_id = model.body(\"box\").id\n",
    "\n",
    "    # Joint indices\n",
    "    all_joints = _ARM_JOINTS + _FINGER_JOINTS\n",
    "    robot_qpos_adr = np.array([model.jnt_qposadr[model.joint(j).id] for j in all_joints])\n",
    "\n",
    "    gripper_pos = data.site_xpos[gripper_site_id]\n",
    "    gripper_mat = data.site_xmat[gripper_site_id].reshape(9)\n",
    "\n",
    "    obj_xmat = data.xmat[obj_body_id].reshape(9)\n",
    "    obj_xpos = data.xpos[obj_body_id]\n",
    "\n",
    "    # WARNING: This likely differs from your MJX training obs. Use only if your ONNX is vector-only.\n",
    "    obs = np.concatenate([\n",
    "        data.qpos[robot_qpos_adr],\n",
    "        data.qvel[robot_qpos_adr],\n",
    "        gripper_pos,\n",
    "        gripper_mat,\n",
    "        obj_xmat,\n",
    "        obj_xpos - gripper_pos,\n",
    "    ]).astype(np.float32)\n",
    "    return obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0bc15a",
   "metadata": {},
   "source": [
    "## Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd458f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy expects image: (128, 128)\n",
      "Policy expects state_dim: 50\n",
      "Starting rollout...\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: rgb for the following indices\n index: 3 Got: 6 Expected: 3\n Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m img_vis \u001b[38;5;241m=\u001b[39m render_rgb(renderer, data, camera\u001b[38;5;241m=\u001b[39mcameras[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Policy action\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Apply action as delta on ctrl (best-effort; adjust to your control mode)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mctrl\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m action\u001b[38;5;241m.\u001b[39msize:\n",
      "Cell \u001b[0;32mIn[7], line 69\u001b[0m, in \u001b[0;36mpolicy_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown ONNX input layout; cannot run. Check sess.get_inputs().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mout_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m/home/junzhe/miniconda3/envs/mujoco_playground/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:287\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    285\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: rgb for the following indices\n index: 3 Got: 6 Expected: 3\n Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "source": [
    "# Load MuJoCo model\n",
    "model = mujoco.MjModel.from_xml_path(XML_PATH)\n",
    "data = mujoco.MjData(model)\n",
    "\n",
    "# Render setup (this is only for visualization; policy input will be resized as needed)\n",
    "# cameras = [\"side\", \"front\"]\n",
    "cameras = [\"side\"]\n",
    "vis_h, vis_w = 480, 640\n",
    "renderer = mujoco.Renderer(model, height=vis_h, width=vis_w)\n",
    "\n",
    "# Control/sim timing\n",
    "ctrl_dt = 0.02\n",
    "sim_dt = 0.005\n",
    "n_substeps = int(round(ctrl_dt / sim_dt))\n",
    "model.opt.timestep = sim_dt\n",
    "\n",
    "# Action scaling (delta-pos style). You may need to tune this.\n",
    "action_scale = 0.04\n",
    "\n",
    "# Determine policy image size if needed\n",
    "if layout[\"mode\"] in (\"image_only\", \"image_state\"):\n",
    "    img_in = layout[\"image\"]\n",
    "    sh = img_in[\"shape\"]\n",
    "    # infer expected H,W from shape\n",
    "    if sh[1] == 3:  # NCHW\n",
    "        H = int(sh[2]); W = int(sh[3])\n",
    "    else:           # NHWC\n",
    "        H = int(sh[1]); W = int(sh[2])\n",
    "    policy_H, policy_W = H, W\n",
    "    print(\"Policy expects image:\", (policy_H, policy_W))\n",
    "else:\n",
    "    policy_H, policy_W = None, None\n",
    "\n",
    "# Determine state dim if needed\n",
    "if layout[\"mode\"] == \"image_state\":\n",
    "    state_dim = int(layout[\"state\"][\"shape\"][1])\n",
    "    print(\"Policy expects state_dim:\", state_dim)\n",
    "else:\n",
    "    state_dim = None\n",
    "\n",
    "def render_multi_view_input():\n",
    "    images = []\n",
    "    for cam in cameras:\n",
    "        img = render_rgb(renderer, data, camera=cam)\n",
    "        img_rs = resize_hwc_uint8(img, policy_H, policy_W)\n",
    "        images.append(img_rs)\n",
    "    if not images:\n",
    "        raise RuntimeError(\"No cameras configured for rendering.\")\n",
    "    return np.concatenate(images, axis=2)\n",
    "\n",
    "def policy_step():\n",
    "    \"\"\"Compute action from current sim state.\"\"\"\n",
    "    feed = {}\n",
    "    if layout[\"mode\"] == \"image_only\":\n",
    "        img_rs = render_multi_view_input()\n",
    "        feed[layout[\"image\"][\"name\"]] = to_onnx_image(img_rs, layout[\"image\"])\n",
    "    elif layout[\"mode\"] == \"image_state\":\n",
    "        img_rs = render_multi_view_input()\n",
    "        feed[layout[\"image\"][\"name\"]] = to_onnx_image(img_rs, layout[\"image\"])\n",
    "\n",
    "        # Default: feed zeros. Replace this with a training-consistent state vector if you trained with state.\n",
    "        state = np.zeros((state_dim,), dtype=np.float32)\n",
    "        feed[layout[\"state\"][\"name\"]] = to_onnx_state(state, layout[\"state\"])\n",
    "    elif layout[\"mode\"] == \"vector_only\":\n",
    "        obs = build_vector_obs(model, data)\n",
    "        feed[layout[\"vector\"][\"name\"]] = obs[None, :].astype(np.float32)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown ONNX input layout; cannot run. Check sess.get_inputs().\")\n",
    "\n",
    "    action = sess.run([out_name], feed)[0][0].astype(np.float32)\n",
    "    return action\n",
    "\n",
    "# Reset to home keyframe if available\n",
    "mujoco.mj_resetData(model, data)\n",
    "key_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_KEY, \"home\")\n",
    "if key_id >= 0:\n",
    "    mujoco.mj_resetDataKeyframe(model, data, key_id)\n",
    "    try:\n",
    "        data.ctrl[:] = model.keyframe(\"home\").ctrl\n",
    "    except Exception:\n",
    "        pass\n",
    "mujoco.mj_forward(model, data)\n",
    "\n",
    "print(\"Starting rollout...\")\n",
    "\n",
    "\n",
    "frames = []\n",
    "T = 10.0  # seconds\n",
    "fps = 30\n",
    "\n",
    "while data.time < T:\n",
    "    # Visualization frame (large)\n",
    "    img_vis = render_rgb(renderer, data, camera=cameras[0])\n",
    "\n",
    "    # Policy action\n",
    "    action = policy_step()\n",
    "\n",
    "    # Apply action as delta on ctrl (best-effort; adjust to your control mode)\n",
    "    if data.ctrl.size == action.size:\n",
    "        data.ctrl[:] = data.ctrl + action_scale * action\n",
    "        # clip to actuator range\n",
    "        ctrl_range = model.actuator_ctrlrange\n",
    "        data.ctrl[:] = np.clip(data.ctrl, ctrl_range[:, 0], ctrl_range[:, 1])\n",
    "    else:\n",
    "        # If dims mismatch, print once and stop\n",
    "        raise RuntimeError(f\"action dim {action.size} != ctrl dim {data.ctrl.size}. Your ONNX likely targets a different action space/control mode.\")\n",
    "\n",
    "    # step physics\n",
    "    for _ in range(n_substeps):\n",
    "        mujoco.mj_step(model, data)\n",
    "\n",
    "    # video sampling\n",
    "    if len(frames) < data.time * fps:\n",
    "        frames.append(img_vis)\n",
    "\n",
    "mediapy.show_video(frames, fps=fps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afde7a",
   "metadata": {},
   "source": [
    "## Save MP4 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec585fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /data/user/junzhe/code/mjpl/mujoco_playground/learning/runs/rgbppo_AirbotPlayPickCube__1__1766164466/onnx_rollout.mp4\n"
     ]
    }
   ],
   "source": [
    "import imageio.v2 as imageio\n",
    "out_mp4 = os.path.join(r\"/data/user/junzhe/code/mjpl/mujoco_playground/learning/runs/debug_pick_init_pos2\", \"onnx_rollout.mp4\")\n",
    "imageio.mimwrite(out_mp4, frames, fps=30, codec=\"libx264\", quality=8)\n",
    "print(\"Wrote:\", out_mp4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a61c9",
   "metadata": {},
   "source": [
    "    ## If your ONNX expects `state`\n",
    "\n",
    "    For **rgb+state** ONNX, you must feed a `state` vector that matches training.\n",
    "    If you exported `policy_rgb_state.onnx` from your MJX wrapper training, the correct `state` is whatever your MJX env provided as `obs[\"state\"]`.\n",
    "    Running the same ONNX inside a standalone MuJoCo XML without reproducing that state definition will usually reduce performance.\n",
    "\n",
    "    If you want **pure-vision** inference, re-export **rgb-only** ONNX and use it here.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
